%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% 
% Generic template for the anteproyectos of TFC/TFM/TFGs
% 
% $Id: anteproyecto.tex,v 1.6 2018/09/11 12:23:48 macias Exp $
% 
% By:
%  + Javier Macías-Guarasa. 
%    Departamento de Electrónica
%    Universidad de Alcalá
%  + Roberto Barra-Chicote. 
%    Departamento de Ingeniería Electrónica
%    Universidad Politécnica de Madrid   
% 
% Based on original sources by Roberto Barra, Manuel Ocaña, Jesús Nuevo,
% Pedro Revenga, Fernando Herránz and Noelia Hernández. Thanks a lot to
% all of them, and to the many anonymous contributors found (thanks to
% google) that provided help in setting all this up.
% 
% See also the additionalContributors.txt file to check the name of
% additional contributors to this work.
% 
% If you think you can add pieces of relevant/useful examples,
% improvements, please contact us at (macias@depeca.uah.es)
% 
% You can freely use this template and please contribute with
% comments or suggestions!!!
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

% This is for rubber to clean additional files
% rubber: clean anteproyecto.acn anteproyecto.acr anteproyecto.alg anteproyecto.cod anteproyecto.ist anteproyecto.out anteproyecto.sbl anteproyecto.slg anteproyecto.sym anteproyecto.lor

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% BEGIN Preamble and configuration section
% 
\input{../Config/preamble-anteproyecto.tex}    % DO NOT TOUCH THIS LINE. You can edit
% the file to modify some default settings

\input{../Config/myconfig.tex}    % DO NOT TOUCH THIS LINE, but EDIT THIS FILE 
                                  % to set your specific settings (related
                                  % to the document language, your degree,
                                  % document details (such as title, author
                                  % (you), your email, name of the tribunal
                                  % members, document year, keyword and
                                  % palabras clave) and link colors), and
                                  % define your commonly used commands
                                  % (some examples are provided).

\input{../Config/postamble-anteproyecto.tex}   % DO NOT TOUCH THIS LINE. Yes, I know,
                                  % "postamble" is not a valid word... :-)

% path to directories containing images
\graphicspath{{../Book/logos/}{../Book/figures/}{../Book/diagrams/}} % Edit this to your
                                  % needs. Only logos is really required
                                  % when you generate your own content.
% 
% END Preamble and configuration section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\title{Anteproyecto de \myWorkTypeFull}        % DO NOT TOUCH THIS LINE
\date{\myThesisProposalDate}                         % DO NOT TOUCH THIS LINE
\author{\myAuthorFullName}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Let's start with the real stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{document}                                   % DO NOT TOUCH THIS LINE

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% BEGIN within-document configuration, frontpage and cover pages generation
% 

% Set Language dependent issues that must be set after \begin{document}
\input{../Config/setlanguagedependentissues.tex} % DO NOT TOUCH THIS LINE
                                                 % NOR THE FILE

% 
% END within-document configuration, frontpage and cover pages generation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\maketitle

\begin{description}                               % DO NOT TOUCH THIS LINE
\item[\expandafter\makefirstuc\expandafter{\wordAutorOrAutora}:] \myAuthorFullName                       % DO NOT TOUCH THIS LINE
\item[\expandafter\makefirstuc\expandafter{\wordTutorOrTutores}:] \myAdvisors                   % DO NOT TOUCH THIS LINE
  \item[Titulación:] \myDegreefull                % DO NOT TOUCH THIS LINE
  \item[Título:] \myBookTitleSpanish              % DO NOT TOUCH THIS LINE
  \ifthenelse{\equal{\myLanguage}{english}}       % DO NOT TOUCH THIS LINE
  {                                               % DO NOT TOUCH THIS LINE
  \item[Título en inglés:] \myBookTitleEnglish    % DO NOT TOUCH THIS LINE
  }                                               % DO NOT TOUCH THIS LINE
  {                                               % DO NOT TOUCH THIS LINE
  }                                               % DO NOT TOUCH THIS LINE
\item[Departamento:] \myDepartment                % DO NOT TOUCH THIS LINE
\end{description}                                 % DO NOT TOUCH THIS LINE

%\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% BEGIN Normal sections. Edit/modify all within this section

\section{Introducción}
\label{sec:introduccion}

En los últimos años, la detección de objetos en tres dimensiones (3D) ha adquirido un papel crucial en el avance de los sistemas de conducción autónoma, representando un desafío significativo para garantizar la precisión y seguridad en la interpretación del entorno. La combinación de sensores LiDAR y cámaras permite capturar tanto información de profundidad como de color y textura, aspectos vitales para una comprensión integral del entorno en el que operan estos sistemas. Sin embargo, los métodos tradicionales que procesan datos cuadro por cuadro presentan limitaciones, como la sensibilidad al ruido, oclusiones y la dispersión de datos, lo que puede afectar la robustez y consistencia de la detección.

Este anteproyecto explora la integración de técnicas de Deep Learning con métodos de fusión temporal que emplean múltiples entradas de sensores, como cámaras y LiDAR, para mejorar la detección de objetos en 3D. Se propone la implementación de un modelo que, inspirado en la arquitectura de detección de objetos Temp-Frustum Net, fusione características de cuadros anteriores mediante un Módulo de Fusión Temporal (TFM). Este módulo permite combinar la información de diferentes instantes de tiempo para compensar las limitaciones de los modelos basados en cuadros individuales, incrementando así la robustez y precisión de la detección ante oclusiones y situaciones complejas de tráfico.

El desarrollo de este sistema se validará utilizando el dataset KITTI, ampliamente reconocido en la investigación de conducción autónoma, y se implementará en dispositivos NVIDIA Jetson para evaluar su viabilidad en entornos hardware de bajo consumo.

\section{Objetivos}
\label{sec:objetivos-y-campo}


El objetivo fundamental de este proyecto es el desarrollo e implementación de un sistema de detección y estimación de objetos en 3D con métodos de Deep Learning que combinen modelos basados en redes neuronales y técnicas de fusión temporal para datos de cámara y LiDAR, validando su desempeño tanto en entornos simulados como en condiciones reales.


Los objetivos específicos de este proyecto son los siguientes:
\begin{itemize}
	\item Estudio y análisis de la arquitectura YOLO y de la red propuesta en el modelo Temp-Frustum Net:
	\begin{enumerate}
		\item Realizar una revisión exhaustiva de la arquitectura YOLO, destacando sus capacidades y limitaciones en la detección y estimación de objetos 3D a partir de imágenes 2D.
		Analizar el funcionamiento de la arquitectura Temp-Frustum Net y sus innovaciones en la integración de características temporales mediante el Módulo de Fusión Temporal (TFM), comprendiendo su aplicación en la detección de objetos en 3D.
	\end{enumerate}
	
	\item Análisis y comprensión del dataset KITTI:
	\begin{enumerate}
		\item Estudiar la estructura, características y contenido del dataset KITTI, evaluando su utilidad para entrenar y validar modelos de detección de objetos en 3D.
		Adaptar y preparar los datos del dataset KITTI para su uso eficiente en los modelos de detección, garantizando una segmentación precisa. 
	\end{enumerate}
	
	\item Implementación y fine-tuning de la arquitectura YOLO para detección 3D:
	\begin{enumerate}
		\item Implementar y adaptar la arquitectura YOLO para su entrenamiento en el dataset KITTI, ajustando sus parámetros y estructura para la estimación tridimensional de objetos.
	\end{enumerate}
	
	\item Desarrollo del Módulo de Fusión Temporal (TFM) y su implementación en el sistema:
	\begin{enumerate}
		\item Integrar el Módulo de Fusión Temporal (TFM) para mejorar la detección 3D mediante el uso de características temporales que provienen de cuadros sucesivos, incrementando la precisión ante oclusiones y situaciones complejas de tráfico con la fusión de datos LiDAR y de cámara.
	\end{enumerate}
	
	\item Validación del sistema en el dataset KITTI:
	\begin{enumerate}
		\item Entrenar y evaluar los modelos implementados utilizando el dataset KITTI, midiendo su precisión y eficiencia en la detección de vehículos, peatones y otros objetos en condiciones de tráfico diversas.
	\end{enumerate}
	
	\item Optimización y mejoras del rendimiento:
	\begin{enumerate}
		\item Implementar estrategias de optimización para reducir los tiempos de inferencia y mejorar la precisión de detección.
	\end{enumerate}
	
\end{itemize}

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=0.6\textwidth]{flujo.png}
	\caption{Flujo del sistema propuesto.}
	\label{fig:flujo_sistema}
\end{figure}



\section{Metodología y plan de trabajo}
\label{sec:metodologia-y-plan}

El proyecto a realizar tiene un duración aproximada de 8 meses, entre noviembre de 2024 y junio de 2025. El desarrollo se divide en fases para el cumplimiento de los objetivos del proyecto descritos en la sección~\ref{sec:objetivos-y-campo}:

\begin{enumerate}
  
\item Formación inicial y revisión del estado del arte (1 mes)
  \begin{itemize}
  \item Estudio de la arquitectura YOLO.
  \item Estudio del framework para machine learning PyTorch.
  \item Consulta bibliográfica de modelos de deteccion de objetos con deep learning y fusion temporal de datos a partir de camaras y LiDAR. 
  \end{itemize}

\item Estudio detallado de la estructura del dataset KITTI (0,5 meses)
\begin{itemize}
	\item Comprension de la organizacion de los datos y objetos incluidos.
	\item Estudio de las matrices de calibración pertenecientes a las cámaras.
	\item Estudio de las nubes de puntos LiDAR.
\end{itemize}
	

\item Implementacion y ajuste de la arquitectura YOLO para la deteccion 3D (2 meses)
  \begin{itemize}
  \item Adaptacion de YOLO para la deteccion 3D.
  \item Realizar fine-tuning para mejorar la precisión.
  \end{itemize}
  

\item Desarrollo del módulo de Fusión Temporal (TFM) y su integración en el sistema (2 meses):
  \begin{itemize}
  \item Integrar técnicas de fusión temporal para aprovechar multiples cuadros de datos.
  \end{itemize}

\item Evaluación y validación del sistema en el dataset KITTI (1 mes)
	\begin{itemize}
		\item Pruebas de validación y analisis de métricas.
	\end{itemize}

\item Optimización y mejora del rendimiento (0,5 meses)
	\begin{itemize}
		\item Aplicación de técnicas de optimización.
	\end{itemize}

\item Documentación y escritura del informe final (1 mes)
	\begin{itemize}
		\item Documentar el proceso, estudios y resultados.
		\item Redacción de la memoria final y presentación de resultados.
	\end{itemize}

\end{enumerate}


\section{Medios}
\label{sec:medios}

Las herramientas necesarias para desarrollar este proyecto de forma correcta
son las siguientes:
\begin{itemize}

\item Componentes Hardware:
	\begin{itemize}
	\item PC con memoria RAM de 32 GB y tarjeta grafica NVIDIA RTX 3060.
	\item Sensores LiDAR y cámaras de alta resolución.
	\end{itemize}

\item Componentes Software:
	\begin{itemize}
	\item Sistema operativo Ubuntu 22.04 LTS.
	\item Lenguaje de programación Python.
	\item Frameworks de Deep Learning: PyTorch
	\item Procesador de textos \LaTeX~\cite para la documentación del proyecto.
	\item Herramientas de control de versiones Git.
	\item Acceso a datasets como KITTI o nuScenes.
	\end{itemize}

\end{itemize}


% 
% END Normal sections. Edit/modify all within this section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{thebibliography}{99}
	\bibitem{ercelik2021tempfrustum}
	E. Ercelik, E. Yurtsever, y A. Knoll,
	\textit{Temp-Frustum Net: 3D Object Detection with Temporal Fusion},
	en \textit{2021 IEEE Intelligent Vehicles Symposium (IV)}, Nagoya, Japón, 2021, pp. 1095-1101.
	
	\bibitem{geiger2013kitti}
	A. Geiger, P. Lenz, C. Stiller, y R. Urtasun,
	``Vision meets Robotics: The KITTI Dataset'',
	\textit{International Journal of Robotics Research (IJRR)}, 2013.
	
	\bibitem{paszke2019pytorch}
	A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, y S. Chintala,
	\textit{PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	preprint, arXiv:1912.01703, 2019. Disponible en: \url{https://arxiv.org/abs/1912.01703}.
	
	\bibitem{redmon2016yolo}
	J. Redmon, S. Divvala, R. Girshick, y A. Farhadi,
	\textit{You Only Look Once: Unified, Real-Time Object Detection},
	preprint, arXiv:1506.02640, 2015. Disponible en: \url{https://arxiv.org/abs/1506.02640}.
	
	
	

	
	
	
	
	
	
	
	
\end{thebibliography}

\input{../Book/biblio/bibliography.tex}               % EDIT this file if required


\end{document}

